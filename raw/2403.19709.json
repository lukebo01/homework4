{
    "S4.T1": {
        "caption": "Table 1 :  Single-task adaptation WER results on voice-search (VS) and voice-search with proper nouns (VS w. PN) test sets. # Params. row shows the number of adapter parameters. Our FFN Head HRA outperforms the full fine-tuning baseline at 12.8M parameters.\n",
        "table": "<figure id=\"S4.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T1.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 1</span>: </span>Single-task adaptation WER results on voice-search (VS) and voice-search with proper nouns (VS w. PN) test sets. # Params. row shows the number of adapter parameters. Our FFN Head HRA outperforms the full fine-tuning baseline at 12.8M parameters.\n</figcaption>\n<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T1.3.1.1.1.1\" class=\"ltx_text\">Model</span></th>\n<td id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"># Params.</td>\n<td id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">VS</td>\n<td id=\"S4.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">VS w. PN</td>\n</tr>\n<tr id=\"S4.T1.3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T1.3.2.2.1.1\" class=\"ltx_text\">Full Fine-tuning</span></th>\n<td id=\"S4.T1.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">1.8B</td>\n<td id=\"S4.T1.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">5.3</td>\n<td id=\"S4.T1.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">15.7</td>\n</tr>\n<tr id=\"S4.T1.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T1.3.3.3.1.1\" class=\"ltx_text\">BitFit</span></th>\n<td id=\"S4.T1.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">1.3M</td>\n<td id=\"S4.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">6.6</td>\n<td id=\"S4.T1.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">18.4</td>\n</tr>\n<tr id=\"S4.T1.3.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"3\"><span id=\"S4.T1.3.4.4.1.1\" class=\"ltx_text\">LoRA</span></th>\n<td id=\"S4.T1.3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2.0M</td>\n<td id=\"S4.T1.3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7.5</td>\n<td id=\"S4.T1.3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">19.9</td>\n</tr>\n<tr id=\"S4.T1.3.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.5.5.1\" class=\"ltx_td ltx_align_center\">4.0M</td>\n<td id=\"S4.T1.3.5.5.2\" class=\"ltx_td ltx_align_center\">6.8</td>\n<td id=\"S4.T1.3.5.5.3\" class=\"ltx_td ltx_align_center\">19.0</td>\n</tr>\n<tr id=\"S4.T1.3.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.6.6.1\" class=\"ltx_td ltx_align_center\">7.9M</td>\n<td id=\"S4.T1.3.6.6.2\" class=\"ltx_td ltx_align_center\">6.4</td>\n<td id=\"S4.T1.3.6.6.3\" class=\"ltx_td ltx_align_center\">18.0</td>\n</tr>\n<tr id=\"S4.T1.3.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"3\"><span id=\"S4.T1.3.7.7.1.1\" class=\"ltx_text\">Residual Adapters</span></th>\n<td id=\"S4.T1.3.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">3.2M</td>\n<td id=\"S4.T1.3.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">6.3</td>\n<td id=\"S4.T1.3.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">17.9</td>\n</tr>\n<tr id=\"S4.T1.3.8.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.8.8.1\" class=\"ltx_td ltx_align_center\">6.4M</td>\n<td id=\"S4.T1.3.8.8.2\" class=\"ltx_td ltx_align_center\">6.2</td>\n<td id=\"S4.T1.3.8.8.3\" class=\"ltx_td ltx_align_center\">17.1</td>\n</tr>\n<tr id=\"S4.T1.3.9.9\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.9.9.1\" class=\"ltx_td ltx_align_center\">12.7M</td>\n<td id=\"S4.T1.3.9.9.2\" class=\"ltx_td ltx_align_center\">5.8</td>\n<td id=\"S4.T1.3.9.9.3\" class=\"ltx_td ltx_align_center\">16.7</td>\n</tr>\n<tr id=\"S4.T1.3.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" rowspan=\"3\"><span id=\"S4.T1.3.10.10.1.1\" class=\"ltx_text\">Linear Head HRA (ours)</span></th>\n<td id=\"S4.T1.3.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">814K</td>\n<td id=\"S4.T1.3.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">6.2</td>\n<td id=\"S4.T1.3.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">17.4</td>\n</tr>\n<tr id=\"S4.T1.3.11.11\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.11.11.1\" class=\"ltx_td ltx_align_center\">6.4M</td>\n<td id=\"S4.T1.3.11.11.2\" class=\"ltx_td ltx_align_center\">5.4</td>\n<td id=\"S4.T1.3.11.11.3\" class=\"ltx_td ltx_align_center\">16.2</td>\n</tr>\n<tr id=\"S4.T1.3.12.12\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.12.12.1\" class=\"ltx_td ltx_align_center\">12.8M</td>\n<td id=\"S4.T1.3.12.12.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.12.12.2.1\" class=\"ltx_text ltx_font_bold\">5.1</span></td>\n<td id=\"S4.T1.3.12.12.3\" class=\"ltx_td ltx_align_center\">15.7</td>\n</tr>\n<tr id=\"S4.T1.3.13.13\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.13.13.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" rowspan=\"3\"><span id=\"S4.T1.3.13.13.1.1\" class=\"ltx_text\">FFN Head HRA (ours)</span></th>\n<td id=\"S4.T1.3.13.13.2\" class=\"ltx_td ltx_align_center ltx_border_t\">1.3M</td>\n<td id=\"S4.T1.3.13.13.3\" class=\"ltx_td ltx_align_center ltx_border_t\">6.0</td>\n<td id=\"S4.T1.3.13.13.4\" class=\"ltx_td ltx_align_center ltx_border_t\">17.1</td>\n</tr>\n<tr id=\"S4.T1.3.14.14\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.14.14.1\" class=\"ltx_td ltx_align_center\">13.6M</td>\n<td id=\"S4.T1.3.14.14.2\" class=\"ltx_td ltx_align_center\">5.2</td>\n<td id=\"S4.T1.3.14.14.3\" class=\"ltx_td ltx_align_center\">15.4</td>\n</tr>\n<tr id=\"S4.T1.3.15.15\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.15.15.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">27.2M</td>\n<td id=\"S4.T1.3.15.15.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.3.15.15.2.1\" class=\"ltx_text ltx_font_bold\">5.1</span></td>\n<td id=\"S4.T1.3.15.15.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.3.15.15.3.1\" class=\"ltx_text ltx_font_bold\">15.3</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 1 reports the WER results from our single-task adaptation experiments. Unless otherwise mentioned, all models were trained for 100K iterations."
        ]
    },
    "S4.T2": {
        "caption": "Table 2 :  Multi-task adaptation WER results on\nEuphonia\ndata sets. Our FFN Head HRA achieves the best WER and closes the gap against full fine-tuning baseline. Figure\u00a0 3  shows that this model has a sub-linear growth in terms of the size of adapter parameters as the number of tasks increases.",
        "table": "<figure id=\"S4.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T2.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 2</span>: </span>Multi-task adaptation WER results on\nEuphonia\ndata sets. Our FFN Head HRA achieves the best WER and closes the gap against full fine-tuning baseline. Figure\u00a0<a href=\"#S4.F3\" title=\"Figure 3 \u2023 4.2 Multi-task Adaptation \u2023 4 Results \u2023 Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of Large Speech Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> shows that this model has a sub-linear growth in terms of the size of adapter parameters as the number of tasks increases.</figcaption>\n<table id=\"S4.T2.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T2.3.1.1.1.1\" class=\"ltx_text\">Model</span></th>\n<td id=\"S4.T2.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"># Params.</td>\n<td id=\"S4.T2.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Mean</td>\n<td id=\"S4.T2.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">Median</td>\n<td id=\"S4.T2.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">SD</td>\n</tr>\n<tr id=\"S4.T2.3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T2.3.2.2.1.1\" class=\"ltx_text\">USM Basemodel</span></th>\n<td id=\"S4.T2.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">-</td>\n<td id=\"S4.T2.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">31.5</td>\n<td id=\"S4.T2.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">21.8</td>\n<td id=\"S4.T2.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">28.6</td>\n</tr>\n<tr id=\"S4.T2.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T2.3.3.3.1.1\" class=\"ltx_text\">Full Fine-tuning</span></th>\n<td id=\"S4.T2.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">232B</td>\n<td id=\"S4.T2.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">9.3</td>\n<td id=\"S4.T2.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5.4</td>\n<td id=\"S4.T2.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">11.1</td>\n</tr>\n<tr id=\"S4.T2.3.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"3\"><span id=\"S4.T2.3.4.4.1.1\" class=\"ltx_text\">LoRA</span></th>\n<td id=\"S4.T2.3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">201M</td>\n<td id=\"S4.T2.3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">10.9</td>\n<td id=\"S4.T2.3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.6</td>\n<td id=\"S4.T2.3.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">12.4</td>\n</tr>\n<tr id=\"S4.T2.3.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.5.5.1\" class=\"ltx_td ltx_align_center\">403M</td>\n<td id=\"S4.T2.3.5.5.2\" class=\"ltx_td ltx_align_center\">10.9</td>\n<td id=\"S4.T2.3.5.5.3\" class=\"ltx_td ltx_align_center\">7.4</td>\n<td id=\"S4.T2.3.5.5.4\" class=\"ltx_td ltx_align_center\">11.6</td>\n</tr>\n<tr id=\"S4.T2.3.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.6.6.1\" class=\"ltx_td ltx_align_center\">805M</td>\n<td id=\"S4.T2.3.6.6.2\" class=\"ltx_td ltx_align_center\">12.4</td>\n<td id=\"S4.T2.3.6.6.3\" class=\"ltx_td ltx_align_center\">6.9</td>\n<td id=\"S4.T2.3.6.6.4\" class=\"ltx_td ltx_align_center\">15.8</td>\n</tr>\n<tr id=\"S4.T2.3.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"3\"><span id=\"S4.T2.3.7.7.1.1\" class=\"ltx_text\">Residual Adapters</span></th>\n<td id=\"S4.T2.3.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">410M</td>\n<td id=\"S4.T2.3.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">10.2</td>\n<td id=\"S4.T2.3.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.1</td>\n<td id=\"S4.T2.3.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">11.6</td>\n</tr>\n<tr id=\"S4.T2.3.8.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.8.8.1\" class=\"ltx_td ltx_align_center\">819M</td>\n<td id=\"S4.T2.3.8.8.2\" class=\"ltx_td ltx_align_center\">10.2</td>\n<td id=\"S4.T2.3.8.8.3\" class=\"ltx_td ltx_align_center\">6.1</td>\n<td id=\"S4.T2.3.8.8.4\" class=\"ltx_td ltx_align_center\">11.2</td>\n</tr>\n<tr id=\"S4.T2.3.9.9\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.9.9.1\" class=\"ltx_td ltx_align_center\">1.6B</td>\n<td id=\"S4.T2.3.9.9.2\" class=\"ltx_td ltx_align_center\">10.1</td>\n<td id=\"S4.T2.3.9.9.3\" class=\"ltx_td ltx_align_center\">6.2</td>\n<td id=\"S4.T2.3.9.9.4\" class=\"ltx_td ltx_align_center\">11.0</td>\n</tr>\n<tr id=\"S4.T2.3.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" rowspan=\"3\"><span id=\"S4.T2.3.10.10.1.1\" class=\"ltx_text\">Linear Head HRA</span></th>\n<td id=\"S4.T2.3.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">51M</td>\n<td id=\"S4.T2.3.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">14.6</td>\n<td id=\"S4.T2.3.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">9.7</td>\n<td id=\"S4.T2.3.10.10.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">14.2</td>\n</tr>\n<tr id=\"S4.T2.3.11.11\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.11.11.1\" class=\"ltx_td ltx_align_center\">102M</td>\n<td id=\"S4.T2.3.11.11.2\" class=\"ltx_td ltx_align_center\">14.5</td>\n<td id=\"S4.T2.3.11.11.3\" class=\"ltx_td ltx_align_center\">9.9</td>\n<td id=\"S4.T2.3.11.11.4\" class=\"ltx_td ltx_align_center\">13.1</td>\n</tr>\n<tr id=\"S4.T2.3.12.12\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.12.12.1\" class=\"ltx_td ltx_align_center\">203M</td>\n<td id=\"S4.T2.3.12.12.2\" class=\"ltx_td ltx_align_center\">16.1</td>\n<td id=\"S4.T2.3.12.12.3\" class=\"ltx_td ltx_align_center\">12.0</td>\n<td id=\"S4.T2.3.12.12.4\" class=\"ltx_td ltx_align_center\">12.1</td>\n</tr>\n<tr id=\"S4.T2.3.13.13\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.13.13.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" rowspan=\"3\"><span id=\"S4.T2.3.13.13.1.1\" class=\"ltx_text\">FFN Head HRA</span></th>\n<td id=\"S4.T2.3.13.13.2\" class=\"ltx_td ltx_align_center ltx_border_t\">201M</td>\n<td id=\"S4.T2.3.13.13.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.3.13.13.3.1\" class=\"ltx_text ltx_font_bold\">9.9</span></td>\n<td id=\"S4.T2.3.13.13.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.3</td>\n<td id=\"S4.T2.3.13.13.5\" class=\"ltx_td ltx_align_center ltx_border_t\">11.2</td>\n</tr>\n<tr id=\"S4.T2.3.14.14\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.14.14.1\" class=\"ltx_td ltx_align_center\">403M</td>\n<td id=\"S4.T2.3.14.14.2\" class=\"ltx_td ltx_align_center\">10.2</td>\n<td id=\"S4.T2.3.14.14.3\" class=\"ltx_td ltx_align_center\">6.1</td>\n<td id=\"S4.T2.3.14.14.4\" class=\"ltx_td ltx_align_center\">11.8</td>\n</tr>\n<tr id=\"S4.T2.3.15.15\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.15.15.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">806M</td>\n<td id=\"S4.T2.3.15.15.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">10.4</td>\n<td id=\"S4.T2.3.15.15.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">6.2</td>\n<td id=\"S4.T2.3.15.15.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">11.3</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 2 reports the WER results from our multi task adaptation experiments. We build golden baseline from USM model with full model fine-tuning on each speaker respectively, and each model is fine-tuned with data from its corresponding speaker only. For the adapter configurations, we parameterize adapters by a speaker-id and learnable one-hot embedding. Following [26], we introduce one-hot-embedding lookup table with entries through one-on-one mapping to corresponding speakers. During training, we randomly select data samples from the 128 speakers in each batch. The recurrent controller network is shared across all 128 speakers while a separate adapter head is inserted for each speaker for specialization. For adapter baseline, we choose to experiment with LoRA and Residual Adapters since it showed a promising performance in the single-task adaptation setup (Section 4.1)."
        ]
    },
    "S4.T3": {
        "caption": "Table 3 :  Online adaptation WER results on\nEuphonia\ndata sets. Our FFN Head HRA (S) with pre-trained controller achieves comparable results against the regular setup (only 0.2% WER loss). Paired T-Test shows no statistically significant difference between with and without pre-trained controller.",
        "table": "<figure id=\"S4.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T3.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 3</span>: </span>Online adaptation WER results on\nEuphonia\ndata sets. Our FFN Head HRA (S) with pre-trained controller achieves comparable results against the regular setup (only 0.2% WER loss). Paired T-Test shows no statistically significant difference between with and without pre-trained controller.</figcaption>\n<table id=\"S4.T3.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.3.1.1.1.1\" class=\"ltx_text\">Model</span></th>\n<th id=\"S4.T3.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"># Params.</th>\n<th id=\"S4.T3.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Mean</th>\n<th id=\"S4.T3.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Paired T-Test</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.3.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"3\"><span id=\"S4.T3.3.2.1.1.1\" class=\"ltx_text\">Linear Head HRA</span></td>\n<td id=\"S4.T3.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">51M</td>\n<td id=\"S4.T3.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">10.6</td>\n<td id=\"S4.T3.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">-</td>\n</tr>\n<tr id=\"S4.T3.3.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.3.2.1\" class=\"ltx_td ltx_align_center\">102M</td>\n<td id=\"S4.T3.3.3.2.2\" class=\"ltx_td ltx_align_center\">10.9</td>\n<td id=\"S4.T3.3.3.2.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.3.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.4.3.1\" class=\"ltx_td ltx_align_center\">203M</td>\n<td id=\"S4.T3.3.4.3.2\" class=\"ltx_td ltx_align_center\">11.0</td>\n<td id=\"S4.T3.3.4.3.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.3.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"3\"><span id=\"S4.T3.3.5.4.1.1\" class=\"ltx_text\">FFN Head HRA</span></td>\n<td id=\"S4.T3.3.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">201M</td>\n<td id=\"S4.T3.3.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.3.5.4.3.1\" class=\"ltx_text ltx_font_bold\">9.9</span></td>\n<td id=\"S4.T3.3.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S4.T3.3.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.6.5.1\" class=\"ltx_td ltx_align_center\">403M</td>\n<td id=\"S4.T3.3.6.5.2\" class=\"ltx_td ltx_align_center\">10.2</td>\n<td id=\"S4.T3.3.6.5.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.3.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.7.6.1\" class=\"ltx_td ltx_align_center\">806M</td>\n<td id=\"S4.T3.3.7.6.2\" class=\"ltx_td ltx_align_center\">10.4</td>\n<td id=\"S4.T3.3.7.6.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T3.3.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"3\"><span id=\"S4.T3.3.8.7.1.1\" class=\"ltx_text\">\n<span id=\"S4.T3.3.8.7.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.T3.3.8.7.1.1.1.1\" class=\"ltx_p\">Linear Head HRA</span>\n<span id=\"S4.T3.3.8.7.1.1.1.2\" class=\"ltx_p\">(w/ pre-trained</span>\n<span id=\"S4.T3.3.8.7.1.1.1.3\" class=\"ltx_p\">controller)</span>\n</span></span></td>\n<td id=\"S4.T3.3.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">51M</td>\n<td id=\"S4.T3.3.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">10.7</td>\n<td id=\"S4.T3.3.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.59</td>\n</tr>\n<tr id=\"S4.T3.3.9.8\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.9.8.1\" class=\"ltx_td ltx_align_center\">101M</td>\n<td id=\"S4.T3.3.9.8.2\" class=\"ltx_td ltx_align_center\">11.0</td>\n<td id=\"S4.T3.3.9.8.3\" class=\"ltx_td ltx_align_center\">0.25</td>\n</tr>\n<tr id=\"S4.T3.3.10.9\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.10.9.1\" class=\"ltx_td ltx_align_center\">202M</td>\n<td id=\"S4.T3.3.10.9.2\" class=\"ltx_td ltx_align_center\">11.3</td>\n<td id=\"S4.T3.3.10.9.3\" class=\"ltx_td ltx_align_center\">0.03</td>\n</tr>\n<tr id=\"S4.T3.3.11.10\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.11.10.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"3\"><span id=\"S4.T3.3.11.10.1.1\" class=\"ltx_text\">\n<span id=\"S4.T3.3.11.10.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.T3.3.11.10.1.1.1.1\" class=\"ltx_p\">FFN Head HRA</span>\n<span id=\"S4.T3.3.11.10.1.1.1.2\" class=\"ltx_p\">(w/ pre-trained</span>\n<span id=\"S4.T3.3.11.10.1.1.1.3\" class=\"ltx_p\">controller)</span>\n</span></span></td>\n<td id=\"S4.T3.3.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\">118M</td>\n<td id=\"S4.T3.3.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.3.11.10.3.1\" class=\"ltx_text ltx_font_bold\">10.1</span></td>\n<td id=\"S4.T3.3.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.17</td>\n</tr>\n<tr id=\"S4.T3.3.12.11\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.12.11.1\" class=\"ltx_td ltx_align_center\">269M</td>\n<td id=\"S4.T3.3.12.11.2\" class=\"ltx_td ltx_align_center\">10.3</td>\n<td id=\"S4.T3.3.12.11.3\" class=\"ltx_td ltx_align_center\">0.14</td>\n</tr>\n<tr id=\"S4.T3.3.13.12\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.13.12.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">672M</td>\n<td id=\"S4.T3.3.13.12.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">10.5</td>\n<td id=\"S4.T3.3.13.12.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.22</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 3 reports the WER results from our multi task adaptation experiments with and without pre-trained controller. We hand picked an extra 128\nEuphonia\nspeaker data as out-of-domain data with respect to the in-domain 128\nEuphonia\nspeaker data mentioned above. We divide the training into two steps. First step, we pre-train the recurrent controller network with out-of-domain data. Second step, we freeze the recurrent controller network, use in-domain data to train the adapter head with random initialization. So the number of actual training parameter is reduced in this setup as we only train the adapter head. Furthermore, this approach provides a solution for sensitive data sets that cannot be trained within one model. If we pre-train the recurrent controller network only on non-Personal Identifiable Information (PII) data, and parameterize the adapter head by speaker, then no speaker needs to share tuning parameters with others."
        ]
    },
    "S4.T4": {
        "caption": "Table 4 :  Linear Head HRA ablation results.",
        "table": "<figure id=\"S4.T4\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T4.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 4</span>: </span>Linear Head HRA ablation results.</figcaption>\n<table id=\"S4.T4.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Model variant</th>\n<th id=\"S4.T4.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"># Params.</th>\n<th id=\"S4.T4.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VS</th>\n<th id=\"S4.T4.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VS w. PN</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.3.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">Linear Head HRA</th>\n<td id=\"S4.T4.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">3.2M</td>\n<td id=\"S4.T4.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">5.7</td>\n<td id=\"S4.T4.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">16.7</td>\n</tr>\n<tr id=\"S4.T4.3.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">- Recurrent state</th>\n<td id=\"S4.T4.3.3.2.2\" class=\"ltx_td ltx_align_center\">3.2M</td>\n<td id=\"S4.T4.3.3.2.3\" class=\"ltx_td ltx_align_center\">5.9</td>\n<td id=\"S4.T4.3.3.2.4\" class=\"ltx_td ltx_align_center\">16.8</td>\n</tr>\n<tr id=\"S4.T4.3.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 - Weight unshared</th>\n<td id=\"S4.T4.3.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">102.4M</td>\n<td id=\"S4.T4.3.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">5.3</td>\n<td id=\"S4.T4.3.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">15.5</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Our Linear Head HRA is structurally similar to Residual Adapters. We can obtain Residual Adapters with shared weights by removing the recurrent states of the RNN controller and then further by unshared the weights, we recover the original Residual adapters. In Table 4, we listed the performance for each of the model variants. Removing the recurrent state resulted in a small regression in WER while unshared weights on top of it improved performance but now the number of parameters is more than 100M."
        ]
    },
    "S4.T5": {
        "caption": "Table 5 :  Recurrent controller ablation results.",
        "table": "<figure id=\"S4.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T5.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 5</span>: </span>Recurrent controller ablation results.</figcaption>\n<table id=\"S4.T5.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T5.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Controller variant</th>\n<th id=\"S4.T5.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"># Params.</th>\n<th id=\"S4.T5.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VS</th>\n<th id=\"S4.T5.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">VS w. PN</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.3.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">IndRNN</th>\n<td id=\"S4.T5.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">1.6M</td>\n<td id=\"S4.T5.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">6.0</td>\n<td id=\"S4.T5.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">16.9</td>\n</tr>\n<tr id=\"S4.T5.3.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">RNN</th>\n<td id=\"S4.T5.3.3.2.2\" class=\"ltx_td ltx_align_center\">1.9M</td>\n<td id=\"S4.T5.3.3.2.3\" class=\"ltx_td ltx_align_center\">6.1</td>\n<td id=\"S4.T5.3.3.2.4\" class=\"ltx_td ltx_align_center\">17.1</td>\n</tr>\n<tr id=\"S4.T5.3.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T5.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Light GRU</th>\n<td id=\"S4.T5.3.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">2.4</td>\n<td id=\"S4.T5.3.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">6.0</td>\n<td id=\"S4.T5.3.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">16.9</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We have also performed an ablation on controller RNN architecture. In addition to the IndRNN, we run benchmarks on the standard RNN with t\u200ba\u200bn\u200bh\ud835\udc61\ud835\udc4e\ud835\udc5b\u210etanh activation and Light GRU [27] as controller. The results are summarized in Table 5. IndRNN and Light GRU both are competitive whereas the RNN with t\u200ba\u200bn\u200bh\ud835\udc61\ud835\udc4e\ud835\udc5b\u210etanh activation underperformed. This confirms that the choice of controller architecture is crucial in our HRA adapters."
        ]
    }
}