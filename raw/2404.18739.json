{
    "S1.T1": {
        "caption": "Table 1:  14 types of dog vocalizations together with the corresponding number of segments and duration.",
        "table": "<figure id=\"S1.T1\" class=\"ltx_table\">\n<div id=\"S1.T1.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:336.6pt;height:211.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-42.1pt,26.4pt) scale(0.8,0.8) ;\">\n<table id=\"S1.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S1.T1.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Context</th>\n<th id=\"S1.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\"># segments</th>\n<th id=\"S1.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\">Duration (sec)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S1.T1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Very aggressive barking at a stranger (L-S2)</td>\n<td id=\"S1.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\">2,843</td>\n<td id=\"S1.T1.1.1.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\">2,778.66</td>\n</tr>\n<tr id=\"S1.T1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Normal barking at a stranger (L-S1)</td>\n<td id=\"S1.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_right\">2,772</td>\n<td id=\"S1.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_right\">2,512.92</td>\n</tr>\n<tr id=\"S1.T1.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Barking due to assault on the owner (L-A)</td>\n<td id=\"S1.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_right\">829</td>\n<td id=\"S1.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_right\">956.58</td>\n</tr>\n<tr id=\"S1.T1.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Negative grunt (during the presence of a stranger) (GR-N)</td>\n<td id=\"S1.T1.1.1.5.4.2\" class=\"ltx_td ltx_align_right\">637</td>\n<td id=\"S1.T1.1.1.5.4.3\" class=\"ltx_td ltx_align_right\">746.60</td>\n</tr>\n<tr id=\"S1.T1.1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Negative squeal (during the presence of a stranger) (CH-N)</td>\n<td id=\"S1.T1.1.1.6.5.2\" class=\"ltx_td ltx_align_right\">298</td>\n<td id=\"S1.T1.1.1.6.5.3\" class=\"ltx_td ltx_align_right\">546.72</td>\n</tr>\n<tr id=\"S1.T1.1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Sadness/anxiety barking (L-TA)</td>\n<td id=\"S1.T1.1.1.7.6.2\" class=\"ltx_td ltx_align_right\">288</td>\n<td id=\"S1.T1.1.1.7.6.3\" class=\"ltx_td ltx_align_right\">200.27</td>\n</tr>\n<tr id=\"S1.T1.1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Positive squeal (during gameplay) (CH-P)</td>\n<td id=\"S1.T1.1.1.8.7.2\" class=\"ltx_td ltx_align_right\">91</td>\n<td id=\"S1.T1.1.1.8.7.3\" class=\"ltx_td ltx_align_right\">150.49</td>\n</tr>\n<tr id=\"S1.T1.1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Barking during play (L-P)</td>\n<td id=\"S1.T1.1.1.9.8.2\" class=\"ltx_td ltx_align_right\">76</td>\n<td id=\"S1.T1.1.1.9.8.3\" class=\"ltx_td ltx_align_right\">51.21</td>\n</tr>\n<tr id=\"S1.T1.1.1.10.9\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Barking due to stimulation when walking (L-PA)</td>\n<td id=\"S1.T1.1.1.10.9.2\" class=\"ltx_td ltx_align_right\">62</td>\n<td id=\"S1.T1.1.1.10.9.3\" class=\"ltx_td ltx_align_right\">84.06</td>\n</tr>\n<tr id=\"S1.T1.1.1.11.10\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Barking in fear at a stranger (L-S3)</td>\n<td id=\"S1.T1.1.1.11.10.2\" class=\"ltx_td ltx_align_right\">54</td>\n<td id=\"S1.T1.1.1.11.10.3\" class=\"ltx_td ltx_align_right\">45.08</td>\n</tr>\n<tr id=\"S1.T1.1.1.12.11\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.12.11.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Positive grunt (during gameplay) (GR-P)</td>\n<td id=\"S1.T1.1.1.12.11.2\" class=\"ltx_td ltx_align_right\">51</td>\n<td id=\"S1.T1.1.1.12.11.3\" class=\"ltx_td ltx_align_right\">79.56</td>\n</tr>\n<tr id=\"S1.T1.1.1.13.12\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.13.12.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Barking arrival of the owner at home (L-H)</td>\n<td id=\"S1.T1.1.1.13.12.2\" class=\"ltx_td ltx_align_right\">24</td>\n<td id=\"S1.T1.1.1.13.12.3\" class=\"ltx_td ltx_align_right\">26.20</td>\n</tr>\n<tr id=\"S1.T1.1.1.14.13\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.14.13.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Barking that is neither playful nor strange (L-O)</td>\n<td id=\"S1.T1.1.1.14.13.2\" class=\"ltx_td ltx_align_right\">9</td>\n<td id=\"S1.T1.1.1.14.13.3\" class=\"ltx_td ltx_align_right\">9.50</td>\n</tr>\n<tr id=\"S1.T1.1.1.15.14\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.15.14.1\" class=\"ltx_td ltx_align_left ltx_border_r\">Non-dog sounds (voices, TV, cars, appliances, etc.) (S)</td>\n<td id=\"S1.T1.1.1.15.14.2\" class=\"ltx_td ltx_align_right\">8,755</td>\n<td id=\"S1.T1.1.1.15.14.3\" class=\"ltx_td ltx_align_right\">14,304.05</td>\n</tr>\n<tr id=\"S1.T1.1.1.16.15\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.1.16.15.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S1.T1.1.1.16.15.1.1\" class=\"ltx_text ltx_font_smallcaps\">Total</span></td>\n<td id=\"S1.T1.1.1.16.15.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_t\">16,789</td>\n<td id=\"S1.T1.1.1.16.15.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_t\">22,491</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>14 types of dog vocalizations together with the corresponding number of segments and duration.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We use a dataset consisting of recordings of 74 dogs, collected in Tepic (Mexico) and Puebla (Mexico), at the homes of the dogs\u2019 owners. A subset of this dataset was previously used by P\u00e9rez-Espinosa et al. (2018). The dog vocalizations were recorded while being exposed to different stimuli (e.g., stranger, play, see Table 1). The recordings were conducted using a video camera Sony CX405 Handycam; in this work, we only use the audio recordings, obtained using the built-in microphone on the camera. The audio codec is A52 stereo with a sampling rate of 48,000 Hz and a bit rate of 256 kbps. The protocol for obtaining the dog vocalizations used in this study was designed and validated by experts in animal behavior from the Tlaxcala Center for Behavioral Biology in Mexico.",
            "Table 1 shows the fourteen labels used in the annotation, along with the corresponding statistics for the number of segments and total duration.",
            "In this task, we predict the context of the bark; i.e., we determine the association between a dog vocalization and its surrounding. Because of the highly skewed label distribution (see Table 1), we focus on the contexts for which more examples are available: very aggressive barking at a stranger (L-S2); normal barking at a stranger (L-S1); negative squeal (in the presence of a stranger) (CH-N); negative grunt (in the presence of a stranger) (GR-N). We do not include barking due to assault on the owner (L-A) because in early experiments we found that the model cannot distinguish it from the very aggressive barking at a stranger (L-S2)."
        ]
    },
    "S4.T2": {
        "caption": "Table 2:  Accuracy for the dog recognition task.",
        "table": "<figure id=\"S4.T2\" class=\"ltx_table\">\n<div id=\"S4.T2.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:145.5pt;height:52.8pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-18.2pt,6.6pt) scale(0.8,0.8) ;\">\n<table id=\"S4.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\">Method</th>\n<th id=\"S4.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Accuracy</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Majority</th>\n<td id=\"S4.T2.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">5.03%</td>\n</tr>\n<tr id=\"S4.T2.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Wav2Vec2 (from scratch)</th>\n<td id=\"S4.T2.1.1.3.2.2\" class=\"ltx_td ltx_align_center\">23.74%</td>\n</tr>\n<tr id=\"S4.T2.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">Wav2Vec2 (pre-trained)</th>\n<td id=\"S4.T2.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.1.1.4.3.2.1\" class=\"ltx_text ltx_font_bold\">49.95%</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Accuracy for the dog recognition task.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 2 shows the results, where we apply the Wav2Vec2 model to dog identification. Our results are in line with the results from P\u00e9rez-Espinosa et al. (2018); Moln\u00e1r et al. (2009), and demonstrate that effectiveness of acoustic representations to discriminate between individual dogs. Further, we find that a model pre-trained on human speech significantly outperforms the model trained from scratch."
        ]
    },
    "S4.T3": {
        "caption": "Table 3:  Accuracy and F-1 measure for dog breed identification.",
        "table": "<figure id=\"S4.T3\" class=\"ltx_table\">\n<div id=\"S4.T3.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:289.9pt;height:66pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-36.2pt,8.2pt) scale(0.8,0.8) ;\">\n<table id=\"S4.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\"></th>\n<th id=\"S4.T3.1.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\"></th>\n<th id=\"S4.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"3\">F-1 measure</th>\n</tr>\n<tr id=\"S4.T3.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\">Method</th>\n<th id=\"S4.T3.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Acc.</th>\n<th id=\"S4.T3.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Chihuahua</th>\n<th id=\"S4.T3.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">French Poodle</th>\n<th id=\"S4.T3.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Schnauzer</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Majority</th>\n<td id=\"S4.T3.1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">58.76%</td>\n<td id=\"S4.T3.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">61.49%</td>\n<td id=\"S4.T3.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.59%</td>\n<td id=\"S4.T3.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">6.78%</td>\n</tr>\n<tr id=\"S4.T3.1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Wav2Vec2 (from scratch)</th>\n<td id=\"S4.T3.1.1.4.2.2\" class=\"ltx_td ltx_align_center\">60.18%</td>\n<td id=\"S4.T3.1.1.4.2.3\" class=\"ltx_td ltx_align_center\">74.42%</td>\n<td id=\"S4.T3.1.1.4.2.4\" class=\"ltx_td ltx_align_center\">14.96%</td>\n<td id=\"S4.T3.1.1.4.2.5\" class=\"ltx_td ltx_align_center\">5.79%</td>\n</tr>\n<tr id=\"S4.T3.1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">Wav2Vec2 (pre-trained)</th>\n<td id=\"S4.T3.1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T3.1.1.5.3.2.1\" class=\"ltx_text ltx_font_bold\">62.28%</span></td>\n<td id=\"S4.T3.1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T3.1.1.5.3.3.1\" class=\"ltx_text ltx_font_bold\">74.47%</span></td>\n<td id=\"S4.T3.1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T3.1.1.5.3.4.1\" class=\"ltx_text ltx_font_bold\">36.11%</span></td>\n<td id=\"S4.T3.1.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T3.1.1.5.3.5.1\" class=\"ltx_text ltx_font_bold\">14.88%</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Accuracy and F-1 measure for dog breed identification.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The results are shown in Table 3. Wav2Vec2 trained from scratch outperforms most baselines. As before, we obtain an additional significant boost in performance when pre-training on human speech data. The variation in individual breeds can be explained by the unbalanced number of observations per breed, with Chihuahua being the most common breed in our dataset (57%), followed by French Poodle (28%) and Schnauzer (15%)."
        ]
    },
    "S4.T4": {
        "caption": "Table 4:  Accuracy and F-1 measure for context grounding.",
        "table": "<figure id=\"S4.T4\" class=\"ltx_table\">\n<div id=\"S4.T4.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:275.9pt;height:66pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-34.5pt,8.2pt) scale(0.8,0.8) ;\">\n<table id=\"S4.T4.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\"></th>\n<th id=\"S4.T4.1.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\"></th>\n<th id=\"S4.T4.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"4\">F-1 measure</th>\n</tr>\n<tr id=\"S4.T4.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\">Method</th>\n<th id=\"S4.T4.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Acc.</th>\n<th id=\"S4.T4.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">L-S2</th>\n<th id=\"S4.T4.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">CH-N</th>\n<th id=\"S4.T4.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">GR-N</th>\n<th id=\"S4.T4.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">L-S1</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Majority</th>\n<td id=\"S4.T4.1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">56.37%</td>\n<td id=\"S4.T4.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">41.31%</td>\n<td id=\"S4.T4.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.00%</td>\n<td id=\"S4.T4.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.00%</td>\n<td id=\"S4.T4.1.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">30.39%</td>\n</tr>\n<tr id=\"S4.T4.1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Wav2Vec2 (from scratch)</th>\n<td id=\"S4.T4.1.1.4.2.2\" class=\"ltx_td ltx_align_center\">58.45%</td>\n<td id=\"S4.T4.1.1.4.2.3\" class=\"ltx_td ltx_align_center\">49.26%</td>\n<td id=\"S4.T4.1.1.4.2.4\" class=\"ltx_td ltx_align_center\">21.26%</td>\n<td id=\"S4.T4.1.1.4.2.5\" class=\"ltx_td ltx_align_center\">78.20%</td>\n<td id=\"S4.T4.1.1.4.2.6\" class=\"ltx_td ltx_align_center\">48.64%</td>\n</tr>\n<tr id=\"S4.T4.1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">Wav2Vec2 (pre-trained)</th>\n<td id=\"S4.T4.1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.1.5.3.2.1\" class=\"ltx_text ltx_font_bold\">62.18%</span></td>\n<td id=\"S4.T4.1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.1.5.3.3.1\" class=\"ltx_text ltx_font_bold\">49.66%</span></td>\n<td id=\"S4.T4.1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.1.5.3.4.1\" class=\"ltx_text ltx_font_bold\">45.26%</span></td>\n<td id=\"S4.T4.1.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.1.5.3.5.1\" class=\"ltx_text ltx_font_bold\">90.70%</span></td>\n<td id=\"S4.T4.1.1.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.1.5.3.6.1\" class=\"ltx_text ltx_font_bold\">51.13%</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Accuracy and F-1 measure for context grounding.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 4 shows the results. Similar to the previous experiments, both Wav2Vec2 models outperform the majority baseline, with the Wav2Vec2 pre-trained on human speech leading to the most accurate results."
        ]
    },
    "S4.T5": {
        "caption": "Table 5:  Accuracy and F-1 measure for dog gender identification.",
        "table": "<figure id=\"S4.T5\" class=\"ltx_table\">\n<div id=\"S4.T5.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:206.9pt;height:66pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-25.9pt,8.2pt) scale(0.8,0.8) ;\">\n<table id=\"S4.T5.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T5.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\"></th>\n<th id=\"S4.T5.1.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\"></th>\n<th id=\"S4.T5.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\">F-1 measure</th>\n</tr>\n<tr id=\"S4.T5.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\">Method</th>\n<th id=\"S4.T5.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Acc.</th>\n<th id=\"S4.T5.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Female</th>\n<th id=\"S4.T5.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Male</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Majority</th>\n<td id=\"S4.T5.1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">68.70%</td>\n<td id=\"S4.T5.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">74.73%</td>\n<td id=\"S4.T5.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">7.76%</td>\n</tr>\n<tr id=\"S4.T5.1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Wav2Vec2 (from scratch)</th>\n<td id=\"S4.T5.1.1.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.1.1.4.2.2.1\" class=\"ltx_text ltx_font_bold\">70.07%</span></td>\n<td id=\"S4.T5.1.1.4.2.3\" class=\"ltx_td ltx_align_center\">76.54%</td>\n<td id=\"S4.T5.1.1.4.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.1.1.4.2.4.1\" class=\"ltx_text ltx_font_bold\">19.29%</span></td>\n</tr>\n<tr id=\"S4.T5.1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">Wav2Vec2 (pre-trained)</th>\n<td id=\"S4.T5.1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\">68.90%</td>\n<td id=\"S4.T5.1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T5.1.1.5.3.3.1\" class=\"ltx_text ltx_font_bold\">79.31%</span></td>\n<td id=\"S4.T5.1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\">7.10%</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Accuracy and F-1 measure for dog gender identification.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 5 shows the results. The Wav2Vec2 model trained from scratch performs better than the baseline model, with no further improvements obtained with Wav2Vec2 pre-trained on human speech. Interestingly, we do see an improvement brought by human speech pre-training on the female class, for which we have significantly more data in our dataset (67.95% female vs 32.04% male by total duration). We found that gender identification is the most difficult task among all the tasks we propose. We hypothesize that the model trained from scratch focuses on learning acoustic features, while the pre-trained wav2vec attempts to learn shortcuts and overfits quickly. We noticed that it often predicts just the majority class (female) so that F1 increases for female and decreases for male, while the overall accuracy is almost the same as for the majority baseline."
        ]
    }
}