{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiziamo le statistiche dei json di sorgente di 10 papers scelti casualmente, in quanto numero di tabelle, e numero di references e footnotes di ogni tabella, identificandole con nome del paper (filename del json) + id table per avere una panoramica generale iniziale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of tables per file:\n",
      "2403.19709.json: 5\n",
      "2404.16905.json: 3\n",
      "2404.18739.json: 5\n",
      "2405.13001.json: 4\n",
      "2406.07914.json: 3\n",
      "2407.02052.json: 4\n",
      "2408.13739.json: 6\n",
      "2409.02041.json: 3\n",
      "2409.09785.json: 4\n",
      "2409.11252.json: 3\n",
      "\n",
      "Total number of tables: 40\n"
     ]
    }
   ],
   "source": [
    "# Percorso alla cartella contenente i file JSON\n",
    "folder_path = 'raw'\n",
    "\n",
    "# Lista per mantenere i dati estratti\n",
    "data = []\n",
    "\n",
    "# Dizionario per tenere traccia del numero di tabelle per file\n",
    "tables_per_file = {}\n",
    "\n",
    "# Itera attraverso ogni file nella cartella specificata\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Apri e leggi il contenuto del file JSON\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = json.load(file)\n",
    "        \n",
    "        # Conta le tabelle in questo file\n",
    "        num_tables = len(content)\n",
    "        tables_per_file[filename] = num_tables\n",
    "\n",
    "        # Estrai il numero di riferimenti e note per ogni tabella\n",
    "        for table_id, table_content in content.items():\n",
    "            num_references = len(table_content.get('references', []))\n",
    "            num_footnotes = len(table_content.get('footnotes', []))\n",
    "            \n",
    "            # Aggiungi i dati estratti alla lista\n",
    "            data.append({\n",
    "                'File': filename,\n",
    "                'Table ID': table_id,\n",
    "                'Number of References': num_references,\n",
    "                'Number of Footnotes': num_footnotes\n",
    "            })\n",
    "\n",
    "# Converti la lista in un DataFrame per una migliore visualizzazione\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mostra il conteggio delle tabelle per file\n",
    "print(\"\\nNumber of tables per file:\")\n",
    "total_tables = 0\n",
    "for file, count in tables_per_file.items():\n",
    "    print(f\"{file}: {count}\")\n",
    "    total_tables += count\n",
    "\n",
    "# Stampa il totale delle tabelle\n",
    "print(\"\\nTotal number of tables:\", total_tables)\n",
    "\n",
    "# Opzionale: salvare il DataFrame in un file CSV\n",
    "df.to_csv('summary_of_tables.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo notare come abbiamo per i 10 papers selezionati, ben 40 tabelle totali.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappa esterna per categorizzare le colonne\n",
    "COLUMN_MAP = {\n",
    "    \"measure_terms\": [\n",
    "        \"Baseline accuracy (GPT3.5-turbo)\",\n",
    "        \"VS\",\n",
    "        \"VS w. PN\",\n",
    "        \"Baseline accuracy (traditional)\",\n",
    "        \"Accuracy\",\n",
    "        \"Mean\",\n",
    "        \"Median\",\n",
    "        \"SD\",\n",
    "        \"F1\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"w-avg F1\",\n",
    "        \"Test Pos.F1*\",\n",
    "        \"Test Pos.F1\",\n",
    "        \"Eval Pos.F1**\",\n",
    "        \"Œîd‚àò\\u200b(MAE)‚Üì‚ÜìsuperscriptsubscriptŒîùëë(MAE)absent\\\\Delta_{d}^{\\\\circ}\\\\text{(MAE)}\\\\downarrow\",\n",
    "        \"Œîd‚àò\\u200b(MAE)‚Üì‚Üì\\\\Delta_{d}^{\\\\circ}\\\\text{(MAE)}\\\\downarrow\",\n",
    "        \"Œîa‚àò‚Üì\",\n",
    "        \"Œîe‚àò‚Üì\",\n",
    "        \"Œîd‚àò(MAE)\",\n",
    "        \"WER%‚Üì‚Üì\\\\downarrow\",\n",
    "        \"sWER%‚Üì‚Üì\\\\downarrow\",\n",
    "        \"SR%‚Üë‚Üë\\\\uparrow\",\n",
    "        \"CER%\",\n",
    "        \"DER%\",\n",
    "        \"cpCER%\",\n",
    "        \"MOS-N (CI)\",\n",
    "        \"MOS-C (CI)\",\n",
    "        \"BLEU\",\n",
    "        \"ROUGE-L\",\n",
    "        \"METEOR\",\n",
    "        \"BERTScore\",\n",
    "        \"WER\",\n",
    "        \"Pitch mean\",\n",
    "        \"Pitch STD\",\n",
    "        \"Energy mean\",\n",
    "        \"Energy STD\",\n",
    "        \"HTN ratio\",\n",
    "        \"Speaker similarity\",\n",
    "        \"RTF\",\n",
    "        \"Delay\",\n",
    "        \"TcpWER (%)\",\n",
    "         \"WER (%)\",  \n",
    "        \"cpWER (%)\", \n",
    "        \"Unweighted Accuracy (%)\",\n",
    "        \"WER\",  \n",
    "        \"Read Speech (ARL) WER\", \n",
    "        \"Read Speech (CSaLT) WER\",\n",
    "        \"Conversational Speech WER\"\n",
    "    ],\n",
    "    \"specification_terms\": [\n",
    "        \"TED talk\",\n",
    "        \"BBC audio\",\n",
    "        \"Number of Speakers\",\n",
    "        \"WSJ\",\n",
    "        \"Schnauzer\",\n",
    "        \"whisper-medium\",\n",
    "        \"Light GRU\",\n",
    "        \"North West Regions\",\n",
    "        \"test\",\n",
    "        \"Wav2Vec2 (from scratch)\",\n",
    "        \"Source\",\n",
    "        \"CH-N\",\n",
    "        \"North Sindh\",\n",
    "        \"mms-1b\",\n",
    "        \"L-S2\",\n",
    "        \"Telephone\",\n",
    "        \"Category\",\n",
    "        \"Family\",\n",
    "        \"# Params.\",\n",
    "        \"whisper-large\",\n",
    "        \"Chihuahua\",\n",
    "        \"FFN Head HRA\",\n",
    "        \"w/ IV (``Before'') & ST.\",\n",
    "        \"Source Transcript\",\n",
    "        \"French Poodle\",\n",
    "        \"seamless-large\",\n",
    "        \"Female\",\n",
    "        \"Duration (sec)\",\n",
    "        \"USM Basemodel\",\n",
    "        \"Task-2 Baseline\",\n",
    "        \"Male\",\n",
    "        \"Accented English\",\n",
    "        \"whisper-small\",\n",
    "        \"System\",\n",
    "        \"South Punjab\",\n",
    "        \"Whisper-1.5B (first-pass) w/o LM\",\n",
    "        \"Wav2Vec2 (pre-trained)\",\n",
    "        \"Paired T-Test\",\n",
    "        \"Number of samples (four emotions)\",\n",
    "        \"Business news\",\n",
    "        \"Airline info.\",\n",
    "        \"Training set\",\n",
    "        \"Full Fine-tuning\",\n",
    "        \"Mean\",\n",
    "        \"Test set\",\n",
    "        \"L-S1\",\n",
    "        \"Spatial LibriSpeech [22]\",\n",
    "        \"Domain\",\n",
    "        \"Capital Area\",\n",
    "        \"Data\",\n",
    "        \"Total\",\n",
    "        \"Model\",\n",
    "        \"Audiobooks\",\n",
    "        \"SR%‚Üë‚Üë\\\\uparrow\",\n",
    "        \"North Punjab\",\n",
    "        \"mms-300m\",\n",
    "        \"BitFit\",\n",
    "        \"GR-N\",\n",
    "        \"Residual Adapters\",\n",
    "        \"w/ IV\",\n",
    "        \"Noise\",\n",
    "        \"South Sindh\",\n",
    "        \"Controller variant\",\n",
    "        \"- Weight unshared\",\n",
    "        \"Linear Head HRA\",\n",
    "        \"- Recurrent state\",\n",
    "        \"Tedlium-3\",\n",
    "        \"LoRA\",\n",
    "        \"Baluchistan\",\n",
    "        \"w/ IV (``Before'')\",\n",
    "        \"Linear Head HRA (ours)\",\n",
    "        \"Model variant\",\n",
    "        \"w/ IV (``After'')\",\n",
    "        \"Context\",\n",
    "        \"seamless-medium\",\n",
    "        \"train\",\n",
    "        \"IndRNN\",\n",
    "        \"Number of samples (all)\",\n",
    "        \"LRS2\",\n",
    "        \"Accent\",\n",
    "        \"dev\",\n",
    "        \"10.43\",\n",
    "        \"whisper-base\",\n",
    "        \"ATIS\",\n",
    "        \"FFN Head HRA (ours)\",\n",
    "        \"CORAAL\",\n",
    "        \"Method\",\n",
    "        \"eval\",\n",
    "        \"9.61\",\n",
    "        \"LibriSpeech\",\n",
    "        \"CommonVoice\",\n",
    "        \"whisper-tiny\",\n",
    "        \"RNN\",\n",
    "        \"CHiME4\",\n",
    "        \"Majority\",\n",
    "        \"Acc.\",\n",
    "        \"F-1 measure\",\n",
    "        \"NùëÅN-best Oracle\",\n",
    "        \"Interview\",\n",
    "        \"w/o IV\",\n",
    "        \"SwitchBoard\",\n",
    "        \"# segments\",\n",
    "         \"Iteration\",\n",
    "        \"Data(hrs)\",\n",
    "        \"wavLM+conformer ED\",\n",
    "        \"conv2d+ebranchformer ED\",\n",
    "        \"Fusion\",\n",
    "        \"ID\",\n",
    "        \"Model based on Accent-ASR\",\n",
    "        \"Dev\",\n",
    "        \"Eval\",\n",
    "        \"Model\",\n",
    "        \"Metric\",\n",
    "        \"Corpus\", \n",
    "        \"Sample Scale\", \n",
    "        \"Sys-1 RTTM\", \n",
    "        \"Sys-2 RTTM\", \n",
    "        \"Sys-3 RTTM\", \n",
    "        \"Sys-4 RTTM\", \n",
    "        \"NSD\", \n",
    "        \"Re-clustering\", \n",
    "        \"JDS\",\n",
    "        \"train\", \n",
    "        \"test\", \n",
    "        \"Domain\", \n",
    "        \"Source\", \n",
    "        \"Training Set\", \n",
    "        \"Test Set\", \"# Pairs\", \"Length\", \n",
    "        \"System\", \"dev\", \n",
    "        \"eval\",  \n",
    "        \"Number of samples (all)\", \n",
    "        \"Number of samples (four emotions)\",  \n",
    "        \"Baseline accuracy (GPT3.5-turbo)\", \n",
    "        \"Baseline accuracy (traditional)\",\n",
    "        \"Family\", \n",
    "        \"Model\",  \n",
    "        \"Accent\", \n",
    "        \"Number of Speakers\",  \n",
    "        \"Read Speech (ARL)\", \n",
    "        \"Read Speech (CSaLT)\", \"Conversational Speech\",\n",
    "        \"Base Model\", \n",
    "        \"Fine-tuned\"  \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione classify_table classifica una tabella HTML in base alla sua struttura (numero di righe, colonne, e intestazioni multiple) e al contesto fornito da caption e references.\n",
    "\n",
    "La logica √®:\n",
    "\n",
    "Analisi della struttura della tabella:\n",
    "\n",
    "- Determina il numero di righe e colonne.\n",
    "- Verifica la presenza di intestazioni nidificate (rowspan, colspan) per identificare tabelle complesse.\n",
    "\n",
    "Analisi del contesto testuale:\n",
    "\n",
    "- Controlla se i termini di misura (es. \"Accuracy\") o specifica (es. \"Model\") sono menzionati nel caption o nelle references.\n",
    "\n",
    "Classificazione:\n",
    "\n",
    "- Se la tabella ha intestazioni multiple e relazioni complesse ‚Üí \"Cross-Nested\" o \"Nested Relational\".\n",
    "- Se i termini di misura sono trovati solo nel contesto ‚Üí \"Cross-table\".\n",
    "- Tabelle semplici con pi√π righe e colonne ‚Üí \"Relational\".\n",
    "- Altri casi o errore ‚Üí \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_table(table_html, caption, references):\n",
    "    \"\"\"\n",
    "    Classifica il tipo di tabella in base alla struttura HTML e al contesto (caption e references).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(table_html, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        if not table:\n",
    "            return \"Unknown\"\n",
    "\n",
    "        rows = table.find_all('tr')\n",
    "        num_rows = len(rows)\n",
    "        num_cols = len(rows[0].find_all(['th', 'td'])) if rows else 0\n",
    "\n",
    "        # Identifica la struttura multi-intestazione\n",
    "        headers = table.find_all('th')\n",
    "        has_multi_header = any(header.get('rowspan') or header.get('colspan') for header in headers)\n",
    "\n",
    "        # Recupera termini di misura e specifica dalla caption/references\n",
    "        combined_text = (caption or \"\") + \" \" + \" \".join(references or [])\n",
    "        context_mentions_measure = any(term.lower() in combined_text.lower() for term in COLUMN_MAP[\"measure_terms\"])\n",
    "        context_mentions_specification = any(term.lower() in combined_text.lower() for term in COLUMN_MAP[\"specification_terms\"])\n",
    "\n",
    "        # Logica di classificazione\n",
    "        if num_rows > 1 and num_cols > 1:\n",
    "            if has_multi_header:\n",
    "                # Controlla per Nested Relational\n",
    "                if any('rowspan' in header.attrs for header in headers) or any('colspan' in header.attrs for header in headers):\n",
    "                    return \"Nested Relational\"\n",
    "                # Controlla per Cross-Nested\n",
    "                return \"Cross-Nested\"\n",
    "            else:\n",
    "                # Differenziazione tra Relational e Cross-table\n",
    "                if context_mentions_measure and not context_mentions_specification:\n",
    "                    return \"Cross-table\"\n",
    "                return \"Relational\"\n",
    "        elif num_rows > 1 and num_cols == 1:\n",
    "            # Tabelle con una sola colonna e pi√π righe\n",
    "            return \"Nested Relational\"\n",
    "        elif num_rows == 1 and num_cols > 1:\n",
    "            # Tabelle con una sola riga di dati e pi√π colonne\n",
    "            return \"Cross-table\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante la classificazione della tabella: {e}\")\n",
    "        return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def deduce_measure(caption, references):\n",
    "    \"\"\"\n",
    "    Deduce the Measure from the caption and references.\n",
    "    \"\"\"\n",
    "    measure_terms = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"WER\", \"BLEU\"]\n",
    "    combined_text = (caption or \"\") + \" \" + \" \".join(references or [])\n",
    "    for term in measure_terms:\n",
    "        if term.lower() in combined_text.lower():\n",
    "            return term\n",
    "    return \"Unknown Measure\"\n",
    "\n",
    "def debug_table_content(headers, cells, row_idx, table_id, file_name):\n",
    "    \"\"\"\n",
    "    Print debug information about inconsistent table rows.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Inconsistent row in table {table_id} of file {file_name}\")\n",
    "    print(f\"Row index: {row_idx}\")\n",
    "    print(f\"Headers ({len(headers)}): {headers}\")\n",
    "    print(f\"Cells ({len(cells)}): {cells}\")\n",
    "    print(f\"Caption: {table_id}\")\n",
    "\n",
    "def handle_nested_headers(rows):\n",
    "    \"\"\"\n",
    "    Combina intestazioni nidificate in una singola lista di intestazioni utilizzabile.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    for row in rows[:2]:  # Considera le prime due righe come intestazioni nidificate\n",
    "        current_row = [cell.get_text(strip=True) for cell in row.find_all(['th', 'td'])]\n",
    "        if len(headers) < len(current_row):\n",
    "            headers = headers + [\"\"] * (len(current_row) - len(headers))  # Riempie intestazioni mancanti\n",
    "        for i, cell in enumerate(current_row):\n",
    "            headers[i] += \" \" + cell if i < len(headers) else cell\n",
    "    return [header.strip() for header in headers]\n",
    "\n",
    "\n",
    "def extract_relational_claims(table_html, column_map):\n",
    "    \"\"\"\n",
    "    Estrai claims da una tabella relazionale semplice.\n",
    "    \"\"\"\n",
    "    claims = []\n",
    "    soup = BeautifulSoup(table_html, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # Intestazioni\n",
    "    headers = [header.get_text(strip=True) for header in rows[0].find_all(['th', 'td'])]\n",
    "\n",
    "    # Estrai i dati\n",
    "    data_rows = rows[1:]  # Salta l'intestazione\n",
    "    for row_idx, row in enumerate(data_rows):\n",
    "        cells = [cell.get_text(strip=True) for cell in row.find_all('td')]\n",
    "\n",
    "        # Salta righe con mismatch tra celle e intestazioni\n",
    "        if len(cells) < len(headers):\n",
    "            cells += [\"\"] * (len(headers) - len(cells))  # Riempi celle mancanti con stringhe vuote\n",
    "        elif len(cells) > len(headers):\n",
    "            debug_table_content(headers, cells, row_idx, \"Relational\", \"N/A\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        specifications = {}\n",
    "        for i, header in enumerate(headers):\n",
    "            if header in column_map[\"specification_terms\"]:\n",
    "                specifications[str(len(specifications))] = {\"name\": header, \"value\": cells[i]}\n",
    "\n",
    "        for i, header in enumerate(headers):\n",
    "            if header in column_map[\"measure_terms\"]:\n",
    "                claims.append({\n",
    "                    \"specifications\": specifications,\n",
    "                    \"Measure\": header,\n",
    "                    \"Outcome\": cells[i]\n",
    "                })\n",
    "\n",
    "    return claims or [{\n",
    "        \"specifications\": {},\n",
    "        \"Measure\": \"N/A\",\n",
    "        \"Outcome\": \"No valid data\"\n",
    "    }]\n",
    "\n",
    "def extract_nested_relational_claims(table_html, caption, references, column_map):\n",
    "    \"\"\"\n",
    "    Estrai claims da una tabella nidificata relazionale.\n",
    "    \"\"\"\n",
    "    claims = []\n",
    "    soup = BeautifulSoup(table_html, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # Deduce the measure dynamically\n",
    "    measure = deduce_measure(caption, references)\n",
    "\n",
    "    # Identifica le intestazioni nidificate\n",
    "    headers = handle_nested_headers(rows)\n",
    "\n",
    "    # Estrai i dati\n",
    "    data_rows = rows[2:]  # Salta le prime due righe di intestazioni\n",
    "    for row_idx, row in enumerate(data_rows):\n",
    "        cells = [cell.get_text(strip=True) for cell in row.find_all('td')]\n",
    "\n",
    "        if len(cells) < len(headers):\n",
    "            cells += [\"\"] * (len(headers) - len(cells))  # Riempi celle mancanti con stringhe vuote\n",
    "        elif len(cells) > len(headers):\n",
    "            debug_table_content(headers, cells, row_idx, \"Nested Relational\", \"N/A\")\n",
    "            continue\n",
    "\n",
    "        specifications = {}\n",
    "        for i, header in enumerate(headers):\n",
    "            if header in column_map[\"specification_terms\"]:\n",
    "                specifications[str(len(specifications))] = {\"name\": header, \"value\": cells[i]}\n",
    "\n",
    "        for i, header in enumerate(headers):\n",
    "            if header in column_map[\"measure_terms\"]:\n",
    "                claims.append({\n",
    "                    \"specifications\": specifications,\n",
    "                    \"Measure\": measure,\n",
    "                    \"Outcome\": cells[i]\n",
    "                })\n",
    "    return claims or [{\n",
    "        \"specifications\": {\"caption\": caption, \"references\": references},\n",
    "        \"Measure\": \"N/A\",\n",
    "        \"Outcome\": \"No valid data\"\n",
    "    }]\n",
    "\n",
    "\n",
    "def extract_cross_table_claims(table_html, caption, references, column_map):\n",
    "    \"\"\"\n",
    "    Estrai claims da una cross-table.\n",
    "    \"\"\"\n",
    "    claims = []\n",
    "    soup = BeautifulSoup(table_html, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # Deduce the measure dynamically\n",
    "    measure = deduce_measure(caption, references)\n",
    "\n",
    "    # Intestazioni di colonna (Dataset, ad esempio)\n",
    "    col_headers = [cell.get_text(strip=True) for cell in rows[0].find_all(['th', 'td'])[1:]]\n",
    "\n",
    "    # Intestazioni di riga (Metodi, ad esempio)\n",
    "    row_headers = [row.find(['th', 'td']).get_text(strip=True) for row in rows[1:]]\n",
    "\n",
    "    # Estrai i valori\n",
    "    for row_idx, row in enumerate(rows[1:]):\n",
    "        cells = row.find_all('td')[1:]\n",
    "        for col_idx, cell in enumerate(cells):\n",
    "            value = cell.get_text(strip=True)\n",
    "            if value:\n",
    "                claims.append({\n",
    "                    \"specifications\": {\n",
    "                        \"0\": {\"name\": \"Method Name\", \"value\": row_headers[row_idx]},\n",
    "                        \"1\": {\"name\": \"Dataset Name\", \"value\": col_headers[col_idx]}\n",
    "                    },\n",
    "                    \"Measure\": measure,\n",
    "                    \"Outcome\": value\n",
    "                })\n",
    "\n",
    "    return claims or [{\n",
    "        \"specifications\": {\"caption\": caption, \"references\": references},\n",
    "        \"Measure\": \"N/A\",\n",
    "        \"Outcome\": \"No valid data\"\n",
    "    }]\n",
    "\n",
    "\n",
    "def extract_cross_nested_table_claims(table_html, caption, references, column_map):\n",
    "    \"\"\"\n",
    "    Estrai claims da una cross-table nidificata.\n",
    "    \"\"\"\n",
    "    claims = []\n",
    "    soup = BeautifulSoup(table_html, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    if len(rows) < 3:  # Assicuriamoci che ci siano abbastanza righe per analizzare intestazioni e dati\n",
    "        print(\"ERROR: Not enough rows in the table for cross-nested claims.\")\n",
    "        return [{\n",
    "            \"specifications\": {\"caption\": caption, \"references\": references},\n",
    "            \"Measure\": \"N/A\",\n",
    "            \"Outcome\": \"No valid data\"\n",
    "        }]\n",
    "\n",
    "    # Deduce the measure dynamically\n",
    "    measure = deduce_measure(caption, references)\n",
    "\n",
    "    # Intestazioni di colonne nidificate\n",
    "    col_headers = []\n",
    "    try:\n",
    "        for col in zip(*[row.find_all(['th', 'td'])[1:] for row in rows[:2]]):  # Prendi le prime 2 righe per intestazioni\n",
    "            col_headers.append(\" \".join(cell.get_text(strip=True) for cell in col))\n",
    "    except IndexError as e:\n",
    "        print(f\"ERROR: Issue extracting column headers: {e}\")\n",
    "        return [{\n",
    "            \"specifications\": {\"caption\": caption, \"references\": references},\n",
    "            \"Measure\": \"N/A\",\n",
    "            \"Outcome\": \"No valid data\"\n",
    "        }]\n",
    "\n",
    "    # Intestazioni di riga\n",
    "    row_headers = []\n",
    "    try:\n",
    "        for row in rows[2:]:\n",
    "            header_cell = row.find(['th', 'td'])\n",
    "            if header_cell:\n",
    "                row_headers.append(header_cell.get_text(strip=True))\n",
    "    except IndexError as e:\n",
    "        print(f\"ERROR: Issue extracting row headers: {e}\")\n",
    "        return [{\n",
    "            \"specifications\": {\"caption\": caption, \"references\": references},\n",
    "            \"Measure\": \"N/A\",\n",
    "            \"Outcome\": \"No valid data\"\n",
    "        }]\n",
    "\n",
    "    # Estrai i valori\n",
    "    for row_idx, row in enumerate(rows[2:]):\n",
    "        cells = row.find_all('td')[1:]  # Salta la prima cella per considerare i valori\n",
    "        for col_idx, cell in enumerate(cells):\n",
    "            try:\n",
    "                value = cell.get_text(strip=True)\n",
    "                if value:\n",
    "                    claims.append({\n",
    "                        \"specifications\": {\n",
    "                            \"0\": {\"name\": \"Method Name\", \"value\": row_headers[row_idx]},\n",
    "                            \"1\": {\"name\": \"Dataset Name\", \"value\": col_headers[col_idx]}\n",
    "                        },\n",
    "                        \"Measure\": measure,\n",
    "                        \"Outcome\": value\n",
    "                    })\n",
    "            except IndexError as e:\n",
    "                print(f\"ERROR: Issue accessing cell at row {row_idx}, col {col_idx}: {e}\")\n",
    "\n",
    "    return claims or [{\n",
    "        \"specifications\": {\"caption\": caption, \"references\": references},\n",
    "        \"Measure\": \"N/A\",\n",
    "        \"Outcome\": \"No valid data\"\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 1 in file 2403.19709.json\n",
      "Table type: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 2 in file 2403.19709.json\n",
      "Table type: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 3 in file 2403.19709.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 12\n",
      "Processing table 4 in file 2403.19709.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 6\n",
      "Processing table 5 in file 2403.19709.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 6\n",
      "Processing table 1 in file 2404.16905.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 20\n",
      "Processing table 2 in file 2404.16905.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 16\n",
      "Processing table 3 in file 2404.16905.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 8\n",
      "Processing table 1 in file 2404.18739.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 2 in file 2404.18739.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 3\n",
      "Processing table 3 in file 2404.18739.json\n",
      "Table type: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 4 in file 2404.18739.json\n",
      "Table type: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 5 in file 2404.18739.json\n",
      "Table type: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 1 in file 2405.13001.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 2 in file 2405.13001.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 3 in file 2405.13001.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 4 in file 2405.13001.json\n",
      "Table type: Cross-table\n",
      "Number of claims generated: 56\n",
      "Processing table 1 in file 2406.07914.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 5\n",
      "Processing table 2 in file 2406.07914.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 3\n",
      "Processing table 3 in file 2406.07914.json\n",
      "Table type: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 1 in file 2407.02052.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 2 in file 2407.02052.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 3 in file 2407.02052.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 4 in file 2407.02052.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 1 in file 2408.13739.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 2 in file 2408.13739.json\n",
      "Table type: Nested Relational\n",
      "DEBUG: Inconsistent row in table Nested Relational of file N/A\n",
      "Row index: 0\n",
      "Headers (4): ['Train', 'LT Test', 'CT Train', 'Test']\n",
      "Cells (5): ['Total no. of Male Speakers', '21', '3', '20', '6']\n",
      "Caption: Nested Relational\n",
      "DEBUG: Inconsistent row in table Nested Relational of file N/A\n",
      "Row index: 1\n",
      "Headers (4): ['Train', 'LT Test', 'CT Train', 'Test']\n",
      "Cells (5): ['Total no. of Female Speakers', '43', '12', '37', '15']\n",
      "Caption: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 3 in file 2408.13739.json\n",
      "Table type: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 4 in file 2408.13739.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 5 in file 2408.13739.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 6 in file 2408.13739.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 1 in file 2409.02041.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 2 in file 2409.02041.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 3 in file 2409.02041.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 1 in file 2409.09785.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 2 in file 2409.09785.json\n",
      "Table type: Nested Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 3 in file 2409.09785.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 4 in file 2409.09785.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 1 in file 2409.11252.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 2 in file 2409.11252.json\n",
      "Table type: Relational\n",
      "Number of claims generated: 1\n",
      "Processing table 3 in file 2409.11252.json\n",
      "Table type: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 0\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['Base Model', 'Fine-tuned', 'Base Model', 'Fine-tuned', 'Base Model', 'Fine-tuned']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 1\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['', '', '', '', '', '']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 2\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['116.92', '45.59', '96.57', '42.12', '163.18', '59.99']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 3\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['71.53', '39.84', '57.77', '38.86', '163.52', '48.61']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 4\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['48.70', '28.60', '41.10', '27.39', '55.67', '32.92']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 5\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['37.04', '25.38', '33.39', '24.15', '40.22', '28.87']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 6\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['26.25', '23.79', '24.44', '22.35', '18.30', '17.86']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 7\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['-', '51.48', '-', '47.73', '-', '66.40']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 8\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['39.65', '28.37', '34.60', '26.85', '46.44', '42.46']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 9\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['30.06', '19.41', '24.18', '20.59', '22.33', '20.01']\n",
      "Caption: Relational\n",
      "DEBUG: Inconsistent row in table Relational of file N/A\n",
      "Row index: 10\n",
      "Headers (4): ['', 'Read Speech (ARL)', 'Read Speech (CSaLT)', 'Conversational Speech']\n",
      "Cells (6): ['23.97', '17.09', '20.57', '18.61', '29.99', '18.75']\n",
      "Caption: Relational\n",
      "Number of claims generated: 1\n"
     ]
    }
   ],
   "source": [
    "def extract_claims_based_on_table_type(table_html, caption, references, column_map):\n",
    "    \"\"\"\n",
    "    Estrai claims in base al tipo di tabella classificata.\n",
    "    \"\"\"\n",
    "    claims = []\n",
    "    table_type = classify_table(table_html,caption, references)\n",
    "    if table_type == \"Relational\":\n",
    "        claims = extract_relational_claims(table_html, column_map)\n",
    "    elif table_type == \"Nested Relational\":\n",
    "        claims = extract_nested_relational_claims(table_html,caption, references, column_map)\n",
    "    elif table_type == \"Cross-table\":\n",
    "        claims = extract_cross_table_claims(table_html, caption, references, column_map)\n",
    "    elif table_type == \"Cross-Nested\":\n",
    "        claims = extract_cross_nested_table_claims(table_html, caption, references, column_map)\n",
    "    else:\n",
    "        print(\"Unknown table type.\")\n",
    "    return claims\n",
    "\n",
    "def process_json_files(input_folder, output_folder, column_map):\n",
    "    \"\"\"\n",
    "    Analizza tutti i file JSON nella cartella e processa le tabelle.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = json.load(f)\n",
    "\n",
    "            table_id = 1\n",
    "            for table_key, table_data in content.items():\n",
    "                table_html = table_data.get(\"table\", \"\")\n",
    "                caption = table_data.get(\"caption\", \"\")\n",
    "                references = table_data.get(\"references\", [])\n",
    "\n",
    "                # Classifica il tipo di tabella\n",
    "                table_type = classify_table(table_html, caption, references)\n",
    "                print(f\"Processing table {table_id} in file {file_name}\")\n",
    "                print(f\"Table type: {table_type}\")\n",
    "\n",
    "                # Estrai claims\n",
    "                claims = extract_claims_based_on_table_type(\n",
    "                    table_html, caption, references, column_map\n",
    "                )\n",
    "\n",
    "                # Debug: Mostra il numero di claims generati\n",
    "                print(f\"Number of claims generated: {len(claims)}\")\n",
    "                if len(claims) == 0:\n",
    "                    print(f\"WARNING: No claims generated for table {table_id} in file {file_name}\")\n",
    "                    print(f\"Caption: {caption}\")\n",
    "                    print(f\"References: {references}\")\n",
    "\n",
    "                # Salva i claims solo se ce ne sono\n",
    "                if claims:\n",
    "                    output_file = os.path.join(output_folder, f\"{os.path.splitext(file_name)[0]}_{table_id}_claims.json\")\n",
    "                    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "                        # Aggiungi il tipo di tabella come primo nodo nel file JSON\n",
    "                        output_data = {\n",
    "                            \"typeTable\": table_type,\n",
    "                            \"claims\": {str(i): claim for i, claim in enumerate(claims)}\n",
    "                        }\n",
    "                        json.dump(output_data, out_f, indent=4, ensure_ascii=False)\n",
    "                \n",
    "                table_id += 1\n",
    "\n",
    "# Configura i percorsi delle cartelle\n",
    "input_folder = 'raw'  # Cartella di input contenente i file JSON\n",
    "output_folder = 'claims'  # Cartella di output per salvare i claims\n",
    "\n",
    "# Avvia il processo\n",
    "process_json_files(input_folder, output_folder, COLUMN_MAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
