{
    "table": [
        [
            [
                "Unnamed: 0_level_0",
                "Method"
            ],
            [
                "Unnamed: 1_level_0",
                "Acc."
            ],
            [
                "F-1 measure",
                "Female"
            ],
            [
                "F-1 measure",
                "Male"
            ]
        ],
        [
            "Majority",
            "68.70%",
            "74.73%",
            "7.76%"
        ],
        [
            "Wav2Vec2 (from scratch)",
            "70.07%",
            "76.54%",
            "19.29%"
        ],
        [
            "Wav2Vec2 (pre-trained)",
            "68.90%",
            "79.31%",
            "7.10%"
        ]
    ],
    "caption": "Table 5:  Accuracy and F-1 measure for dog gender identification.",
    "references": [
        "Table 5 shows the results. The Wav2Vec2 model trained from scratch performs better than the baseline model, with no further improvements obtained with Wav2Vec2 pre-trained on human speech. Interestingly, we do see an improvement brought by human speech pre-training on the female class, for which we have significantly more data in our dataset (67.95% female vs 32.04% male by total duration). We found that gender identification is the most difficult task among all the tasks we propose. We hypothesize that the model trained from scratch focuses on learning acoustic features, while the pre-trained wav2vec attempts to learn shortcuts and overfits quickly. We noticed that it often predicts just the majority class (female) so that F1 increases for female and decreases for male, while the overall accuracy is almost the same as for the majority baseline."
    ]
}