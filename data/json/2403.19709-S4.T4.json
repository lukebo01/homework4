{
    "table": [
        [
            "Model variant",
            "# Params.",
            "VS",
            "VS w. PN"
        ],
        [
            "Linear Head HRA",
            "3.2M",
            "5.7",
            "16.7"
        ],
        [
            "- Recurrent state",
            "3.2M",
            "5.9",
            "16.8"
        ],
        [
            "- Weight unshared",
            "102.4M",
            "5.3",
            "15.5"
        ]
    ],
    "caption": "Table 4 :  Linear Head HRA ablation results.",
    "references": [
        "Our Linear Head HRA is structurally similar to Residual Adapters. We can obtain Residual Adapters with shared weights by removing the recurrent states of the RNN controller and then further by unshared the weights, we recover the original Residual adapters. In Table 4, we listed the performance for each of the model variants. Removing the recurrent state resulted in a small regression in WER while unshared weights on top of it improved performance but now the number of parameters is more than 100M."
    ]
}